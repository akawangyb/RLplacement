# 干扰感知的边缘容器服务部署问题建模

假设一个边缘服务请求需要消耗6种资源。

假设向量$\vec{t_{r_s}}=(cpu,mem,net^{\uparrow},net^{\downarrow},disk^{read},disk^{write})$表示服务请求$r_s$的6类资源需求

向量$\vec{T_n}=(cpu,mem,net^{\uparrow},net^{\downarrow},disk^{read},disk^{write})$表示服务器$n\in N$的6类资源总量

## 干扰建模

假设容器服务$s\in S$部署在边缘服务器$n\in N$上，容器服务$s$产生的干扰因子为

$$
\delta_{n,s}=DANET_{inference}(\vec{t}_s^{demad},\vec{t}_{s,n}^{supply})
$$

其中，$\vec{t}_s^{demand}$表示容器$s$需要的完成所有请求需要的资源总量，$\vec{t}_{s,n}^{supply}$表示容器$s$部署在服务器$n$上可以提供的资源量。

## 部署建模

1. 边缘服务器的集合为$N$,每个边缘服务器$n$能够提供6种类型的计算资源，分别是cpu资源，内存容量，网络上、下行带宽，磁盘读写带宽,用向量$\vec{T_n}$表示.提供的全部磁盘存储空间为$C_n$
2. 边缘系统提供的容器服务的集合$S$,每个容器服务以容器的形式部署在边缘服务器上，完成所有的服务请求需要占用的计算资源用向量$\vec{t_s}$表示，并且部署一个容器需要占用的磁盘空间为$c_s$,从云端的镜像仓库拉取容器$s$需要的时延为$b_s$
3. 一个服务请求$r_s$需要由对应的容器$s$来完成，完成一个服务请求$s$对应需要的6种计算资源用$\vec{t_{r_s}}$表示

### 需要解决两个问题：

1. 服务部署，即每个边缘服务器上部署哪些容器
2. 请求路由，即每个边缘用户的服务请求该由哪个服务器来完成，是云数据中心亦或是某一个覆盖到的边缘服务器。

用两个变量来表示，这个问题的解：

1. $x_{n,s}=\{0,1\},$表示服务器$n$上是否部署容器$s$
2. $y_{r_s,n_0}=\{0,1\}$,表示关于服务$s$的一个用户请求$r_s$,是否由服务器$n_0$来完成。其中$n_0\in N\cup \{l\}$其中$l$表示云数据中心。

### 约束条件：


1. 所有的用户请求都要有明确的服务器来完成

$$
\sum_{n_0\in N\cup \{l\}} y_{r_s,n_0}=1\qquad \forall r_s \in R
$$



2. 一个边缘服务器要是能完成一个用户请求，必须部署相应的服务

$$
y_{r_s,n}\le x_{n,s} \qquad \forall r_s\in R,\forall n\in N
$$


3. 边缘服务器的部署容器服务必须要满足磁盘容量上限

$$
x_{n,s}c_s\le C_n \qquad \forall n \in N
$$

4. 一个边缘服务器上完成所有用户请求必须满足服务资源上限

   $$
   \vec{t_{r_s}}^{T} y_{r_s,n}\le \vec{T_n}^{T} \qquad \forall r_s \in R
   $$

### 优化目标

优化目标为最小化所有边缘服务的完成时间，

这里的完成时间由三部分组成:

1. 传输时延
2. 处理时延
3. 容器镜像拉取时延

对于第三个镜像拉取时延，是由容器为载体的边缘服务性质决定的，当边缘服务器需要完成一个没有事先部署的容器时，需要先从云端的镜像仓库拉去容器镜像，然后才能提供服务

对于第一个传输时延，在本研究中假设边缘服务器完成服务请求的传输时延为0，而云数据中心的传输时延为L。

对于第二个处理时延，在本研究中假设每个服务请求$r_s$在单独运行时的时间为$t_{solo}$,而在资源受限的边缘服务器中其实际运行时间为$t_{infer}=t_{solo}(\delta_{s}+1)$，在资源充足的云数据中心中，其处理时延不会受到其他应用程序的干扰影响，仍然保持为$t_{solo}$。

因此：

第一，对于$t$时刻的容器部署问题中，部署策略为了最小化全部的服务完成时延，需要在边缘服务器的“快传输”、“受干扰计算”与云数据中心的“慢传输”和“无干扰计算”之间做出一个权衡。

第二，对于从$i-1$时刻的容器部署到$i$时刻的容器部署格局转换中，部署策略需要考虑如何能够最大化地利用上一个时隙的容器部署结果，以最小化容器镜像的拉取时延。

镜像拉取时延的推导

$$
delay_{pulling}=\sum_{n\in N}\sum_{s\in S} b_s(x_{n,s}^{t_i}-x_{n,s}^{t_{i-1}})x_{n,s}^{t_i}
$$

处理时延的推导

$$
delay_{processing}=\sum_{r_s \in R} \sum_{n_0\in N\cup\{l\}} y_{r_s,n_0} t_{r_s,n_0}
\\
if \quad n_0 == l,\quad t_{r_s,l}=t_{solo}^{r_s}
\\
else \quad n_0 \in N ,\quad _{r_s,n}=t_{solo}^{r_s}*(\delta_{s}+1)
\\ hence,
\\delay_{processing}=\sum_{r_s \in R} t_{solo}^{r_s}+\sum_{r_s\in R}\sum_{n\in N} y_{r_s,n}\delta_{n,s}
$$

下一步要解决如何计算$\delta_{n,s}$

$$
\delta_{n,s}=DANET_{inference}(\vec{t}_s^{demad},\vec{t}_{s,n}^{supply})
\\however,\quad \vec{t}_s^{demand}=\sum_{n \in N} y_{r_s,n}\vec{t_{r_s}}
\\meanwhile,\quad \vec{t_{s,n}^{supply}}=\vec{T_n}-\sum_{r_s\in R}\sum_{n\in N} y_{r_s,n} \vec{t_{r_s}} + \vec{t}_s^{demand}
$$

传输时延的推导

$$
delay_{sending}=\sum_{r_s\in R} y_{r_s,l} L
$$

因此，完成所有服务的时延

$$
delay_{total}=delay_{pulling}+delay_{processing}+delay_{sending}
$$

优化目标即为

$$
Target=\min_{x,y} delay_{total}
\\=\sum_{n\in N}\sum_{s\in S} b_s(x_{n,s}^{t_i}-x_{n,s}^{t_{i-1}})x_{n,s}^{t_i}+\sum_{r_s\in R}\sum_{n\in N} y_{r_s,n}\delta_{n,s}+\sum_{r_s\in R} y_{r_s,l} L
$$
